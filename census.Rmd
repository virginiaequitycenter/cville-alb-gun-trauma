---
title: "Exploring Census Data"
author: "Samantha Toet"
date: "2024-06-12"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)

library(ggmap)
library(janitor)
library(magrittr)
library(readxl)
library(sf)
library(tidycensus)
library(tidyverse)

```

# Comparing regional equity variables to gun violence outcomes {.tabset}

```{r get_data, results='hide'}

alb_map <- get_map(c(left = -79, bottom = 37, right = -78, top = 39),
                   maptype = "roadmap", color = "bw")

cville_map <- get_map(c(left = -78.54, bottom = 37.97, right = -78.43, top = 38.1),
                      maptype = "roadmap", color = "bw")

county_codes <- data.frame(code = c(540, 003), name = c("Albemarle County", "Charlottesville City"))
region <- county_codes$code

# Initial variables to explore:
vars <- c("B01003_001",    # population
          "S1701_C03_001", # poverty rate
          "S1701_C03_002", # child poverty rate 
          "S2001_C01_002") #Median personal earnings of all workers with earnings ages 16 and older

dat <- get_acs(geography = "tract",
               variables = vars,
               state = "VA",
               county = region,
               survey = "acs5",
               year = 2022,
               geometry = "TRUE",
               output = "wide")

dat <- dat %>%
  select(-ends_with("M")) %>%
  rename(pop_est = B01003_001E,
         poverty_est = S1701_C03_001E,
         cpov_est = S1701_C03_002E) %>%
  separate_wider_delim(NAME, delim = "; ", names = c("tract", "locality", "state")) %>%
  st_as_sf()

#write_csv(dat, "data/acs_pov.csv")
#dat <- read.csv("data/acs_pov.csv")

```

Initial variables to explore: poverty rate and child poverty rate

Questions: 

- How can we reframe this to not be deficit-based? 
- Would interactivity (i.e. a leaflet output) serve better? 

## Albemarle

Question: would it make sense to remove Cville in this visualization so that it isn't oversaturated? 

```{r alb, out.width="90%"}

alb_long <- dat %>%
  pivot_longer(cols = c(poverty_est, cpov_est))

facet_names <- c(
  cpov_est = "Childhood Poverty",
  poverty_est = "Overall Poverty")

ggmap(alb_map) +
  geom_sf(data = alb_long, 
          aes(fill = value, 
              geometry = geometry), 
          inherit.aes = FALSE, alpha = .8) +
  facet_wrap( ~ name, labeller = as_labeller(facet_names)) +
  scale_fill_viridis_c(direction = -1, 
                       name = "Rate", 
                       labels=function(x) paste0(x,"%")) +
  labs(title = "Poverty Rates in Albemarle County") +
  theme(axis.title = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank())

```

## Charlottesville

Question: does this look stretched out?

```{r cville, out.width="90%"}

cville <- dat %>%
  filter(locality == "Charlottesville city")

cville_long <- cville %>%
  pivot_longer(cols = c(poverty_est, cpov_est))

ggmap(cville_map) +
  geom_sf(data = cville_long, 
          aes(fill = value, 
              geometry = geometry), 
          inherit.aes = FALSE, alpha = .8) +
  facet_wrap( ~ name, labeller = as_labeller(facet_names)) +
  scale_fill_viridis_c(direction = -1, 
                       name = "Rate", 
                       labels=function(x) paste0(x,"%")) +
  labs(title = "Poverty Rates in Charlottesville City") +
  theme(axis.title = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank())

```

# Visualizing Shots Fired Data

Question: which viz best handles overplotting? 

(Note, the original data doesn't include block group info -- so by getting that info we may fix overplotting)

```{r police}

# All incidents of gun violence from 2019 - 2024
all_gv <- read_excel("data/raw/Regional GV Data - 2019-2024 YTD.xlsx", sheet = "ALL GV INCIDENTS") %>%
  clean_names()

shots_fired <- all_gv %>%
  filter(crime_code == "Shots Fired",
         case_disp_verified == "VERIFIED")

shots_fired %<>% mutate(address = paste(street, "Charlottesville VA"))
lon_lat <- geocode(shots_fired$address)
#sum(is.na(lon_lat$lon)) #0 
shots_fired <- bind_cols(shots_fired, lon_lat)

```

## Albemarle {.tabset}

### geom_count

```{r alb_count}
ggmap(alb_map) +
  geom_count(data = shots_fired, aes(x = lon, y = lat, color = after_stat(n)))

```

### statbin2d

```{r alb_bin}

ggmap(alb_map) +
  stat_bin2d(data = shots_fired, aes(x = lon, y = lat), bins = 50) +
  scale_fill_viridis_c(limits = c(1, 5))

```

## Charlottesville {.tabset}

### geom_count

```{r cville_count}
ggmap(cville_map) +
  geom_count(data = shots_fired, aes(x = lon, y = lat, color = after_stat(n)))

```

### statbin2d

```{r cville_stat}

ggmap(cville_map) +
  stat_bin2d(data = shots_fired, aes(x = lon, y = lat), bins = 40) +
  scale_fill_viridis_c(limits = c(1, 15))

```

